# External MHA Transformer - TF.Keras 
An Unofficial Implementation of External Attention in TF 2. Paperwork https://arxiv.org/abs/2105.02358

![](https://user-images.githubusercontent.com/17668390/141291708-7c3cd892-d508-4cca-8306-a8b06a38c158.png)


# Code 

- [Multi-Head External Transformer](https://github.com/innat/DOLG-TensorFlow/blob/main/Code%20Example/DenseNet%20DOLGNet%20Malaria.ipynb) | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1y1aB8wC7U9WtNcSEnXTQ0avQSsa9QxRL?usp=sharing) (beginner)

- Live Notebook: Fork-n-Play [[TF.Keras]: External MHA Transformer Hybrid Model](https://www.kaggle.com/ipythonx/tf-keras-external-mha-transformer-rapis-svr) (itermediate)
